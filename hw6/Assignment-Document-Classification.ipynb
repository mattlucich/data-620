{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f95c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import datasets\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091cdbf",
   "metadata": {},
   "source": [
    "## Assignment: Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cc50f",
   "metadata": {},
   "source": [
    "#### by Matthew Lucich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602690a",
   "metadata": {},
   "source": [
    "First we load the pre-processed news article data. The data is a subset of the POLUSA dataset, which is a compliation of .9 million political English news articles from 2017-2019. My pre-processing which took place as part of my Master's capstone project included filtering out market news, removing instances with null values and with undefined political leanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ff56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polusa = pd.read_csv(\"polusa_2019_5k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431aa0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polusa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91eeec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABC News',\n",
       " 'Breitbart',\n",
       " 'CBS News',\n",
       " 'Fox News',\n",
       " 'HuffPost',\n",
       " 'Los Angeles Times',\n",
       " 'NBC News',\n",
       " 'NPR',\n",
       " 'National Review',\n",
       " 'PBS',\n",
       " 'Reuters',\n",
       " 'Slate',\n",
       " 'The Daily Caller',\n",
       " 'The Guardian',\n",
       " 'The Nation',\n",
       " 'The New York Times',\n",
       " 'The State',\n",
       " 'USA Today',\n",
       " 'Yahoo! News'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_polusa[\"outlet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7e421f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CENTER', 'LEFT', 'RIGHT'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_polusa[\"political_leaning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ba76e",
   "metadata": {},
   "source": [
    "Below we can see we have imbalanced classes with the smallest minority class, RIGHT, making up approximately 16% of the instances. According to [Google ML researchers](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data), this would be considered a moderate imbalanced and is not too far from being considered only a mild imbalance. Therefore, we will move forward without downsampling. If we see the model is never predicting RIGHT or there is exceptionally poor performance on that class we may reconsider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9f2ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CENTER    0.6094\n",
       "LEFT      0.2326\n",
       "RIGHT     0.1580\n",
       "Name: political_leaning, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polusa['political_leaning'].value_counts() / len(df_polusa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96dbe372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>outlet</th>\n",
       "      <th>headline</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>authors</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>head_lead_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4328691</td>\n",
       "      <td>2019-08-27 09:37:19</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>Sweden: Woman Was Cradling Baby When She Was F...</td>\n",
       "      <td>A woman in her 30s was fatally shot in the hea...</td>\n",
       "      <td>A woman in her 30s was fatally shot in the hea...</td>\n",
       "      <td>Chris Tomlinson</td>\n",
       "      <td>www.breitbart.com</td>\n",
       "      <td>https://www.breitbart.com/europe/2019/08/27/sw...</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>Sweden: Woman Was Cradling Baby When She Was F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3883779</td>\n",
       "      <td>2019-08-27 09:38:34</td>\n",
       "      <td>HuffPost</td>\n",
       "      <td>Mormon Leaders Ban Guns In Church</td>\n",
       "      <td>A new church policy prohibits all parishioners...</td>\n",
       "      <td>The Church of Jesus Christ of Latter-day Saint...</td>\n",
       "      <td>Senior Reporter</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>https://www.huffpost.com/entry/mormon-lds-chur...</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>Mormon Leaders Ban Guns In Church###A new chur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         date_publish     outlet  \\\n",
       "0  4328691  2019-08-27 09:37:19  Breitbart   \n",
       "1  3883779  2019-08-27 09:38:34   HuffPost   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Sweden: Woman Was Cradling Baby When She Was F...   \n",
       "1                  Mormon Leaders Ban Guns In Church   \n",
       "\n",
       "                                                lead  \\\n",
       "0  A woman in her 30s was fatally shot in the hea...   \n",
       "1  A new church policy prohibits all parishioners...   \n",
       "\n",
       "                                                body          authors  \\\n",
       "0  A woman in her 30s was fatally shot in the hea...  Chris Tomlinson   \n",
       "1  The Church of Jesus Christ of Latter-day Saint...  Senior Reporter   \n",
       "\n",
       "              domain                                                url  \\\n",
       "0  www.breitbart.com  https://www.breitbart.com/europe/2019/08/27/sw...   \n",
       "1   www.huffpost.com  https://www.huffpost.com/entry/mormon-lds-chur...   \n",
       "\n",
       "  political_leaning                                     head_lead_body  \n",
       "0             RIGHT  Sweden: Woman Was Cradling Baby When She Was F...  \n",
       "1              LEFT  Mormon Leaders Ban Guns In Church###A new chur...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polusa = df_polusa.drop(columns={\"Unnamed: 0\"})\n",
    "df_polusa.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e66fc",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05909281",
   "metadata": {},
   "source": [
    "Convert the text categories, \"LEFT\", \"CENTER\", and \"RIGHT\", to numeric categories, 0, 1, and 2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87551431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformer_format = df_polusa[[\"head_lead_body\", \"political_leaning\"]]\n",
    "convert_to_num = {\"LEFT\": 0, \"CENTER\": 1, \"RIGHT\": 2}\n",
    "df_transformer_format = df_transformer_format.replace({\"political_leaning\": convert_to_num})\n",
    "df_transformer_format = df_transformer_format.rename(columns={\"head_lead_body\":\"text\", \"political_leaning\":\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7ade",
   "metadata": {},
   "source": [
    "Create train, dev test, and test sets. We take a similar approach as suggested for project 3. The news articles (rows) are sorted by time and therefore the classes should be approximately evenly distributed throughout the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2c4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_transformer_format[:4000]\n",
    "df_dev_test = df_transformer_format[-1000:-500]\n",
    "df_test = df_transformer_format[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96301540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_dev_test))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc1dfe",
   "metadata": {},
   "source": [
    "Convert Pandas dataframes into special Huggingface dictionaries, which is preferred by their models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8f4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_dict(df_train)\n",
    "dev_test_dataset = datasets.Dataset.from_dict(df_dev_test)\n",
    "test_dataset = datasets.Dataset.from_dict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11253b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$58,000 reward offered after more than 40 wild burros found shot dead in the Mojave Desert'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[\"text\"][1][:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242c239",
   "metadata": {},
   "source": [
    "Tokenize text of the articles (and headlines and leads) into document embeddings. We enable padding so the vector sizes are uniform and enable truncation to prevent outliers in terms of article length making the vector sizes unnecessarily long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959a1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d2552",
   "metadata": {},
   "source": [
    "Load the distilbert-base-uncased tokenizer. The model is a faster version of the BERT transformer model and was trained on the wikipedia and book corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ae6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a7ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7f885de0baf0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d07ec80b544fd5bb98f1b4f4070220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836332e3bd474074a8bf1a8dfddc07f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4f9f221fbd4317807243c9de05db73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_dev_test = dev_test_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6fa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenized_train.remove_columns(['text'])\n",
    "tokenized_dev_test = tokenized_dev_test.remove_columns(['text'])\n",
    "tokenized_test = tokenized_test.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bd1e2",
   "metadata": {},
   "source": [
    "### Classification Model: distilbert-base-uncased (transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccadafb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8103d",
   "metadata": {},
   "source": [
    "Define our evaluation metrics, which include accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc816f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Sourced from: https://huggingface.co/transformers/v3.0.2/training.html\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, labels=[0, 1, 2])\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afdec7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e433d",
   "metadata": {},
   "source": [
    "Define our trainer, specifying the model, the training set, test set, tokenizer, data collator, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c83db04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a476f73",
   "metadata": {},
   "source": [
    "Fine-tune (train) our model over three Epochs. This ended up taking six hours to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd958203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 5:57:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-500\n",
      "Configuration saved in tmp_trainer/checkpoint-500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1000\n",
      "Configuration saved in tmp_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1500\n",
      "Configuration saved in tmp_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.28275184122721353, metrics={'train_runtime': 21473.7349, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.07, 'total_flos': 1589637132288000.0, 'train_loss': 0.28275184122721353, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3090b",
   "metadata": {},
   "source": [
    "We see the accuracy on the dev test set is approximately 92%, which is 31 percentage points above the majority class rate. We see similar results with the F1 score. Additionally, according to F1, precision, and recall, CENTER seems to be the class that is best predicted. As somewhat expected, the smalles minority class, RIGHT, is has the lowest F1, precision, and recall values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a237702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 08:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.87804878 0.95503876 0.81675393]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.88888889 0.94769231 0.82978723]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.86746988 0.9625     0.80412371]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.35529208183288574,\n",
       " 'eval_accuracy': 0.916,\n",
       " 'eval_f1': array([0.87804878, 0.95503876, 0.81675393]),\n",
       " 'eval_precision': array([0.88888889, 0.94769231, 0.82978723]),\n",
       " 'eval_recall': array([0.86746988, 0.9625    , 0.80412371]),\n",
       " 'eval_runtime': 263.2604,\n",
       " 'eval_samples_per_second': 1.899,\n",
       " 'eval_steps_per_second': 0.239,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d81dd99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "preds_data = trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491922e",
   "metadata": {},
   "source": [
    "Evaluation metrics on the average see slightly decreased performance. Yet predicting LEFT is improved for F1, precision and recall. Conversely, we see RIGHT with diminished performance in the same three metrics. Overall, we have a modest preference towards precision, since it may be in bad form to label an article as biased in a certain direction without high confidence, while missing some biased articles is less crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99fac9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.39563611149787903,\n",
       " 'test_accuracy': 0.904,\n",
       " 'test_f1': array([0.90502793, 0.9519833 , 0.7607362 ]),\n",
       " 'test_precision': array([0.92045455, 0.92307692, 0.80519481]),\n",
       " 'test_recall': array([0.89010989, 0.98275862, 0.72093023]),\n",
       " 'test_runtime': 261.4704,\n",
       " 'test_samples_per_second': 1.912,\n",
       " 'test_steps_per_second': 0.241}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_data.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a14605fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to news-model\n",
      "Configuration saved in news-model/config.json\n",
      "Model weights saved in news-model/pytorch_model.bin\n",
      "tokenizer config file saved in news-model/tokenizer_config.json\n",
      "Special tokens file saved in news-model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir=\"news-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e0d08",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c354c",
   "metadata": {},
   "source": [
    "*Natural Language Processing with Python* by Steven Bird, Ewan Klein, and Edward Loper <br> \n",
    "Text Classification, Huggingface: https://huggingface.co/docs/transformers/tasks/sequence_classification <br>\n",
    "Fine-tuning a model with the Trainer API, Huggingface: https://huggingface.co/course/chapter3/3?fw=pt <br>\n",
    "Loading a Metric, Huggingface: https://huggingface.co/docs/datasets/v1.0.1/loading_metrics.html <br>\n",
    "The POLUSA Dataset by Lukas Gebhard, Felix Hamborg: https://arxiv.org/abs/2005.14024 <br>\n",
    "Imbalanced Data: https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data <br>\n",
    "Multi-Label Classification on Unhealthy Comments, YouTube: https://www.youtube.com/watch?v=vNKIg8rXK6w <br>\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011 <br>\n",
    "Convert pandas dataframe to datasetDict: https://stackoverflow.com/questions/71618974/convert-pandas-dataframe-to-datasetdict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
